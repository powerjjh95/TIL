# PART 1 빅데이터 분석 기획

## CHAPTER 1 빅데이터의 이해

### 1. 빅데이터의 개요 및 활용

1. 빅데이터의 등장 배경

2. 빅데이터의 개념

3. 빅데이터의 특징

4. 빅데이터의 가치
   
   1. 빅데이터의 투입 가치
   
   2. 빅데이터의 활용 가치
   
   3. 빅데이터의 사회ㆍ경제적 가치

5. 가치 측정 이슈
   
   1. 데이터를 활용하는 방식
   
   2. 가치를 창출하는 방식
   
   3. 분석 기술의 발전

6. 빅데이터 가치 선정 프레임워크

7. 데이터 산업의 이해
   
   1. 데이터 처리 시대
   
   2. 데이터 통합 시대
   
   3. 데이터 분석 시대
   
   4. 데이터 연결 시대

8. 빅데이터 조직 및 인력

### 2. 빅데이터 기술 및 제도

1. 빅데이터 플랫폼

2. 빅데이터 분석 프로세스 절차
   
   빅데이터 분석 프로세스 정차는 다음과 같은 단계로 나누어진다.
   
   * 첫 번째 단계는 분석 대상이 되는 데이터를 수집하는 단계이다.
   
   * 두 번째 단계는 수집딘 데이터를 저장하고 관리하는 단계이다.
   
   * 세 번째 단계는 저장 된 빅데이터를 처리하는 단계이다.
   
   * 네 번째 단계는 빅데이터를 분석하는 단계이다.
   
   * 다섯 번째 단계는 분석된 결과를 시각화하고 의미를 도출하여 이용하는 단계이다.
   
   * 여섯 번재 단꼐는 저장된 데이터를 폐기하는 단계이다(<그림. 빅데이터 분석 처리 프로세스> 참조).
   1. 빅데이터 수집
   
   2. 빅데이터 저장
   
   3. 빅데이터 처리
   
   4. 빅데이터 분석
   
   5. 빅데이터 분석 시각화
   
   6. 빅데이터 폐기

3. 빅데이터와 인공지능
   
   1. 인공지능
   
   2. 딥러닝

4. 개인정보 법, 제도
   
   1. 빅데이터 개인정보보호 가이드라인
      
      * 공개된 개인정보 또는 이용내역 정보 등을 전자적으로 설정된 체계에 의해 수집·저장·조합·분석 처리하여 새로운 정보를 생섬함에 있어서 이용자의 프라이버시 등을 보호하고 안전한 이용환경을 조성하는 것을 목적으로 한다.
   
   2. 개인정보 비식별 조치 가이드라인
      
      * 정부 3.0 및 빅에티어 활용 확산에 따른 데이터 활용가치 증대 , 개인정보 보호 강화에 대한 사회적 요구 지속, '보호와 활용'을 동시에 모색하는 세계적 정책 변화에 적극 대응하고자 하는 목적을 가지고 있다. 개인정보를 비식별 조치하여 이용 또는 제공하려는 사업자 등이 준수하여야 할 조치 기준을 제시한 것이다.
   
   3. 데이터 3법
      
      * 데이터 이용을 활성화하는 '개인정보보호법', '정보통신망 이용 촉진 및 정보보호 등에 관한 법률(약칭 : 정보통신망법)', '신용정보의 이용 및 보호에 관한 법률(약칭 : 신용정보법)' 등 3가지 법률을 통칭한다.

## CHAPTER 2 데이터 분석 계획

### 1. 분석 방안 수립

1. 분석 로드맵 설정
   
   * 단계별로 추진하고자 하는 목표를 명확히 정의하고, 추진 과제별 선행과 후행 관계를 고려하여 단계별로 추진 내용을 정렬해야 한다.
     
     - 첫 번째 단계는 데이터 분석 체계 도입이다.
     
     - 두 번째 단계는 데이터 분석 유효성 검증이다.
     
     - 세 번째는 데이터 분석 확산 및 고도화 단계이다.

2. 분석 문제 정의
   
   1. 분석 절차 수립(과제 기획)
      
      1. 문제인식 및 정의
      
      2. 문제 해결을 위한 개념적 대안 설계
      
      3. 데이터 가용성 평가
      
      4. 문제 해결을 위한 논리적 모형 설계
      
      5. 타당성 평가
      
      6. 과제 선정 및 분석계획 수립

3. 데이터 분석 방안
   
   1. 데이터 분석 방안
      
      1. 빅데이터 분석 계획 수립
         
         * 빅데이터 분석 계획을 수립하고자 할 때 중요한 것이 바로 수행 방안의 수립이다.
      
      2. 빅데이터 분석 수행
         
         1. 데이터 수집
            
            * 크롤링과 오픈 API등을 통해 필요한 외부 데이터를 수집할 수 있는 기술을 활용하는 것이 매우 중요하다고 할 수 있다.
         
         2. 데이터 저장
         
         3. 데이터 처리
            
            * 데이터의 정제, 데이터의 통합, 데이터의 축소, 데이터의 변환
   
   2. 데이터 분석 방안 설정
      
      1. 하향식(top-down) 접근 방법
         
         * 하향식 접근 방법은 빅데이터 분석과정을 단계화하여 각 단계에서 수행될 활동들을 명확히 정의·수행하고 산출물을 점검·확인함으로써 성공적인 기획활동을 도모하는 방법론으로 정의할 수 있다.
      
      2. 상향식(bottom-top) 접근 방법
         
         * 전통적인 하향식 문제 해결 방식과 대비되어, 기업에서 보유하고 있는 다양한 원천으로부터 생성되고 다양한 형태로 존재하는 데이터로부터 비즈니스 문제와 빅데이터 문제를 도출하고 통찰력과 지식을 얻고자 하는 접근 방법이다.
      
      3. 프로토타이핑 접근 방법
         
         * 사용자가 정보 요구 사항이나 데이터를 정확히 규정하기 어렵고, 데이터 원천도 명확히 파악하기 어려운 상황에서 일단 분석을 시도해  보고 그 결과를 확인해 가면서 반복적으로 개선해 나가는 방법을 말한다.

### 2. 분석 작업 계획

1. 데이터 확보 계획
   
   * 1. 데이터 확보
     
     2. 빅데이터 활용을 위한 두 가지 전제 조건
        
        1. 데이터 확보
           
           * 데이터 확보를 위해서는 보다 많은 인풋 채널(input channel), 즉 데이터 수집 수단이 있어야 한다.
        
        2. 비즈니스 모델에 대한 발굴
     
     3. 빅데이터 활용
     
     4. 빅데이터 구분
        
        1. 정형화(structured) 데이터 : 일정한 규칙을 갖고 체계적으로 정리된 데이터를 의미한다.
        
        2. 반정형화(semi-structured) 데이터 : 한글이나 마이크로소프트 원드 등으로 작성된 데이터를 의미한다.
        
        3. 비정형화(unstructured) 데이터
           
           * 스마트기기 등을 통해서 형성되는 데이터로 페이스북, 트위터, 카카오톡, 라인 등으로 상호 교류되는 정보가 이에 해당한다.
           
           * 비정형 데이터란 글자 그대로 정형화 되지 않은 데이터로서, 구체적으로 미리 정의된 데이터 모델을 가지고 있지 않은 데이터를 말한다.
   1. 능동적 데이터 수집과 수동적 데이터 수집
   
   2. 내부 데이터 수집과 외부 데이터 수집

2. 분석 절차 및 작업 계획
   
   1. 분석 절차 수립
      
      1. 관련 데이터 수집
      2. 데이터 전처리와 정제
      3. 데이터 분석과 정리 및 처리 결과의 수용
      4. 해석과 결과 제시

## CHAPTER 3 데이터 수집 및 저장 계획

1. 데이터 수집 및 전환
   
   1. 데이터 수집 절차
      
      1. 수집 대상 데이터 선정
         
         1. 수집 대상 데이터 도출
         2. 목록 작성
            1. 가능성 : 해당 데이커가 사용 가능하고 수집 가능한가?
            2. 보안 : 수집 시 개인정보 포함 여부 및 유풀 문제는 없는가?
            3. 정확성 : 활용 목적에 따른 세부 항목들이 적절히 포함되었는가?
            4. 수집 난이도 : 데이터 구축과 정제된 데이터를 적정한 비용으로 확보 가능한가?
            5. 수집 비용 : 데이터 수집에 드는 비용은 얼마인가?
      
      2. 수집 세부계획 작성
         
         1. 데이터 소유 기관 파악 및 협의
         
         2. 데이터 유형 분류 및 확인
         
         3. 수집 기술 선정
            
            1. 주요 수집 기술의 기본 기능과 고려 사항
               
               1. HTTP 수집 : Crawling 수집 기술, Open API 수집 기술
                  
                  * Crawling 수집 기술
                    
                    | 기능                    | 고려사항 |
                    | --------------------- | ---- |
                    | 정보 설정 기능              |      |
                    | 수집 에이전트<br/>(웹 로봇) 기능 |      |
                    | Ranking 등<br/>기타 기능   |      |
                  
                  * Open API 수집 기술
                    
                    | 기능             | 고려사항 |
                    | -------------- | ---- |
                    | 정보 설정 기능       |      |
                    | 수집 에이전트 기능     |      |
                    | RDB 테이블과 매핑 기능 |      |
               
               2. FTP 수집 기술
                  
                  | 기능                  | 고려 사항 |
                  | ------------------- | ----- |
                  | 정보 설정 기능            |       |
                  | 클라이언트와<br/>서버 연결 기능 |       |
                  | 파일 전송 기능            |       |
                  | FTP 보안 기능           |       |
               
               3. M2M Aggregator 수집 기술
               
               4. Log Aggregator 수집 기술
               
               5. RDB Aggregator 수집 기술
            
            2. 데이터 유형에 따른 수집 기술 활용 예
               
               1. 관계형데이터베이스 수집 기술 : 스쿱(Sqoop, SQL to Hadoop)
               
               2. 로그 데이터 수집 기술
               
               3. 웹크롤링 : Scrapy
               
               4. 수집 주기 결정
               
               5. 수집계획서 작성
                  
                  1. 데이터 소스 구성요소
                  
                  2. 수집 주기 구성요소
                  
                  3. 데이터 수집 방법 구성요소
            
            3. 데이터 수집 실행
               
               1. 사전 테스트 진행
               
               2. 데이터 수집 시행
               
               3. 데이터 수집 후 처리
   
   2. 데이터 유형 및 속성 파악
      
      1. 데이터 유형 파악
         
         데이터 유형은 저장 위치별, 구성 형태별, 존재 형태별로 구분된다.
         
         1. 저장 위치별
            
            * 내부 데이터는 수집하는 원천 데이터의 데이터 저장소가 내부 시스템에 있는 데이터를 의미한다.
            * 외부 데이터는 수집하는 원천 데이터의 데이터 저장소가 외부 시스템에 있는 데이터를 의미한다.
            * 어떤 데이터를 가져올 것인가와 생산된 데이터를 수집하는 과정의 안정성이 가장 큰 고려 사항
         
         2. 구성 형태별
         
         3. 존재 형태별
   
   3. 데이터 속성 파악
      
      1. 전통적 데이터
      
      2. 빅데이터
         
         노무라연구소는 인재ㆍ조직, 데이터 처리ㆍ축적ㆍ분석 기술, 데이터(비정형ㆍ정형 데이터)까지 포함하는 광의의 빅데이터를 정의하였다.
         
         1. 규모(Volume)
         
         2. 속도(Velocity)
         
         3. 다양성(Variety)
         
         4. 정확성(Veracity)
         
         5. 가치(Value)
         
         6. 빅데이터 처리
   
   4. 데이터 변환/통합
      
      1. 활동 정의
         
         1. 데이터 필터링
         
         2. 데이터 변환
            
            - 평활화(Smoothing) : 구간화, 군집화
            
            - 집계(Aggregation)
            
            - 일반화(Generlaization)
            
            - 정규화(Normalization) : 최소 - 최대 정규화, z-스코어 정규화, 소수 스케일링
         
         3. 데이터 통합
         
         4. 데이터 축소
      
      2. 변환과 통합 기술 : ETL
         
         * 데이터 변환(transformation)과 관련된 기술들은 데이터 유형 변환 등 데이터 분석이 용이한 형태로 변환하는 기술과 정규화(noramlization), 집합화(aggregation), 요약(summarization), 계층 생성 등의 방법을 활용한다. 대표적인 도구로는 ETL(Extraction/Transformation/Loading)이 있다.
         
         * 데이터 공유를 위한 가장 일반적인 형태는 운영계 시스템의 데이터 복제(replication) 기술과 정보계 시스템을 위한 데이터 웨어하우스의 ETL(Extraction, Transformation, Loading) 프로세스이다.
   
   5. 데이터 비식별화
      
      1. 데이터 보안과 개인정보보보호
         
         사용자 인증, 접근제어, 데이터 암호화, 개인정보 비식별화 및 개인정보 암호화
         
         | 구분        | 설명                                         |
         | --------- | ------------------------------------------ |
         | 사용자 인증    | ID/Password 방식, 일회용 패스워드(OTP) 방식, 통합사용자 인증 |
         | 접근제어      | 강제 접근제어, 임의 접근제어, 역할 기반 접근제어               |
         | 암호화       | DES, AES, RSA, MDS, SHA                    |
         | 개인정보 비식별화 |                                            |
         | 개인정보 암호화  |                                            |
         
         1. 보안관리 필수사항 도출
            
            1. 수집 단계  : 수집되는 데이터에 대한 사전 동의사항 확인
            
            2. 저장 단계 : 데이터의 안전한 저장 및 관리 방안 마련
            
            3. 분석ㆍ활용 단계
            
            4. 폐기
         
         2. 보안관리 조치
            
            1. 접근통제, 차단, 인증, 암호화 등
            
            2. 개인정보 처리
               
               1. 데이터 검증
               
               2. 데이터 인증
               
               3. 사후 모니터링
      
      2. 개인정보보호 중요도 증가
         
         1. 데이터 경제
            
            1. 데이터 가치사슬은 사물과 사람에 대한 데이터 플랫폼(특히 빅데이터 플랫폼)의 구축과 데이터의 개방, 공공 데이터 및 민간데이터에 대한 저장과 유통, 일반 정보 및 개인정보에 대한 분석과 활용을 통해 맞춤형 서비스, 사회 현안 해결, 데이터 기반 의사결정 등 다양한 분야에서 활용하도록 지원하는 데이터 생태계이다.
            
            2. 데이터 가치가 점점 높아지는 것에 대한 대비가 필요하다.
            
            3. 데이터 비식별화
               
               1. 적용 대상
               
               2. 적용시기
            
            4. 데이터가 핵심 자원인 데이터 경제 시대에 데이터 활용은 국가 및 조직의 미래를 결정하는 중요한 요소로 작용한다.
         
         2. 개인정보보호 기술 발전
            
            1. 1세대 - 인식 단계
            
            2. 2세대 - 관리 단계
            
            3. 3세대 - 활용 단계
         
         3. 개인정보 비식별 조치 대상
         
         4. 대인정보 재식별(Re-identification)
         
         5. 개인정보 비식별 조치 표준화
         
         6. 개인정보 식별 및 비식별화 처리를 위한 기술 개발 활용 시 고려 사항
      
      3. 개인정보보호 가이드라인
         
         1. 빅데이터 처리와 개인정보보호에 관한 최초의 가이드라인
         
         2. 개인식별 정보에 대한 철저한 '비식별화' 조치(제3조, 제4조, 제5조 등)
         
         3. 빅데이터 처리 사실ㆍ목적 등의 공개를 통한 투명성 확보(제4조, 제5조, 제6조)
         
         4. 개인정보 재식별 시, 즉시 파기 및 비식별화 조치(제3조, 제6조)
         
         5. 민감정보 및 통신비밀의 수집ㆍ이용ㆍ분석 등 처리 금지(제7조, 제8조)
         
         6. 수집괸 정보의 저장ㆍ관리 시 '기술적ㆍ관리적 보호조치' 시행(제3조 제2항)
      
      4. 비식별화 및 재식별화 조치
         
         1. 개인정보 비식별 조치 가이드 라인
            
            1. 본 가이드라인은
               
               1. 사전검토 단계
               
               2. 비식별 조치 단계
               
               3. 적정성 평가 단계
               
               4. 사후관리 단계
            
            2. 미국, 영국 등의 경우에도
            
            3. 비식별 정보는
            
            4. 현행법에 규정된 제재 수단을 안내하여
         
         2. 비식별 조치의 단계별 조치사항
            
            1. 사전 검토
            
            2. 비식별 조치
            
            3. 적정성 평가
            
            4. 사후관리
         
         3. 비식별 조치 방법
            
            1. 가명처리, 총계 처리, 데이터 삭제, 데이터 범주화, 데이터 마스킹
            
            2. 개인정보처리자는 평가 대상 데이터 명세, 비식별 조치현황, 이용기관의 관리수준 등 적정성 평가에 필요한 기초 자료를 작성해야 한다.
            
            3. 비식별 조치된 정보가 유출되는 경우 다른 정보와 결합하여 식별될 우려가 있으므로 필수적인 보호조치를 이행한다.
               
               1. 관리적 보호조치
               
               2. 기술적 보호조치
      
      5. 개인정보 비식별 조치 기술
         
         1. 데이터 비식별 기술
         
         2. 암호화 도구
            
            1. 동형 암호화(homomorphic encryption)
               
               * 동형 암호는 평문과 암호문에서 같은 성질이 유진된다는 의미로 평문에 대한 연산 결과와 암호문에 대한 연산 결과가 같은 값을 가져 암호화된 개인정보를 풀어보지 않고도 통계분석이 가능한 기술이다.
            
            2. 형태 보존 암호화(format-preserving encryption)
               
               블록암호에 기반하여 특정한 형태의 평문의 값을 동일한 형태의 값으로 변환하는 암호 알고리즘
            
            3. 순서 보존 암호화(order-preserving-encryption)
               
               * 암호화 과정에서 평문의 순서 정보를 보존하는 암호 기술로, 암호화를 통한 데이터 프라이버스 보호와 동시에 데이터 활용성을 보장하는 기술이다.
         
         3. 향상된 프라이버시 보호 모델
            
            1. 주요 처리 기법
               
               1. 가명처리
               
               2. 총계처리
               
               3. 데이터 삭제
               
               4. 데이터 범주화
               
               5. 데이터 마스킹
            
            2. 프라이버시 보호를 위한
               
               1. k-익명성(k-anonymity) : 공개된 데이터에 대한 연결공격(linkage attack) 등 취약점을 방어하기 위해 제안된 프라이버시 보호 모델이다.
               
               2. l-다양성(l-diversity) : k-익명성의 취약점을 보완한 것으로 k-익명성에 대한 두 가지 공격,
               
               3. t-근접성(t-closeness)
            
            3. 차분 프라이버시 모델
            
            4. 익명처리 모델
      
      6. 데이터 변환 후 품질 검증
         
         1. 데이터 품질 표준화 추진 동향
         
         2. 데이터 품질 기준
            
            1. 정형 텍스트 데이터에 대한 일반적인 데이터 품질 기준
               
               <일반적 데이터 품질 기준과 활용 예시>
            
            2. 비정형 텍스트 데이터에 대한 데이터 품질 기준
               
               * 비정형 콘텐츠의 메타데이터는 정형 텍스트 데이터와 품질 특성이 거의 같으나 일반적인 정형 텍스트가 현실 세계에 존재하는 개체나 사건에 대한 내용을 텍스트 데이터로 표현하고 있는 데 반해, 비정형 콘텐츠의 메타데이터는 시스템 내부에 디지털화되어 존재하는 멀티미디어 개체를 표현하고 있다는 점에서 차이가 있다.
                 
                 <콘텐츠 유형 분류 사례>
                 
                 <동영상에 대한 품질 기준 정의 사례>
                 
                 <이미지에 대한 품질 기준 정의 사례>
                 
                 <사운드에 대한 품질 기준 정의 사례>
                 
                 <GIS에 대한 품질 기준 정의 사례>
               
               * 측정 기준의 선정 범위는 품질관리 정책 및 방향에 의해 달라질 수 있으며, 품질 측정 목적에 따라서도 품질 기준 항목 전체 또는 일부 항목으로 측정 기준의 범위를 선택할 수 있다.
               
               * 중요도를 산정하여 측정기준 간의 가중치를 정의하는 방법은 사전정의(predefined) 방식이나 임의적(ad-hoc) 방식으로 이루어질 수 있다.
               
               * 측정항목을 작성한다.
               
               * 품질 측정 및 품질 지수를 산출한다.

2. 데이터 적재와 저장
   
   1. 데이터 적재
      
      * 데이터를 수집하고, 변환하고, 적재하는 일련의 과정을 정제라고 부른다.
      
      * 추출(Extraction)은 소스 데이터베이스로부터 데이터를 읽어 내는 과정이며, 변환(Transformation)은 소스로부터 추출된 데이터와 최종 원하는 데이터의 구성 및 형태를 연결하는 과정이다. 적재(Loading)는 타깃 데이터베이스로 데이터를 저장하는 과정이다.
      1. 초기 적재(Initial Loading)
      
      2. 변경 데이터 적재(Changed Data Capture
   
   2. 데이터 저장
      
      1. 데이터 저장처리 절차
         
         * * 1. (DB 구축 및 테스트 수행)
             
             2. (저장처리 및 모니터링)
             
             3. (저장처리 및 모니터링)
         1. 데이터 저장 계획 수립
            
            1. 데이터 유형 검토
               
               1. RDB
               
               2. NoSQL
               
               3. 분산 파일시스템
            
            2. 저장 공간 용량 설계
               
               1. RDB는 레코드 및 최대 저장 기간 등
               
               2. RDB는 솔루션별 가용 공간
               
               3. NoSQL과 분산 파일시스템은
               
               4. NoSQL 및 분산 파일시스템
            
            3. 계획서 작성
         
         2. DB 구축 및 테스트 수행
         
         3. 저장처리 및 모니터링 수행
      
      2. 활용기술
         
         1. RDB 저장 방식
         
         2. NoSQL 저장 방식
         
         3. 분산 파일시스템 저장 방식

# PART 02 빅데이터 탐색

## CHAPTER 1 데이터 전처리

### 1. 데이터 전처리

1. 데이터 정제
   
   데이터 절제는 정형 데이터에서 측정값이 빠져 있다거나, 형식이 다르다거나, 내용 자체가 틀린 데이터를 수정하는 활동을 말한다.
   
   1. 빅데이터 전후처리(Pro-processing)
      
      1. 필터링
      
      2. 유형 변환
      
      3. 정제
   
   2. 빅데이터 후처리(Post-processing)
   
   3. 데이터 전후처리 기술 고려 사항
      
      <데이터 전처리 기술 고려 사항>
      
      <데이터 후처리 기술 고려 사항>

2. 데이터 정제 절차
   
   1. 데이터 특성 파악
   
   2. 데이터 모순점 발견
   
   3. 데이터 수정 변환

### 2. 데이터 결측값(Missing Values) 처리

* 1. 결측값 구분
  
  2. 데이터 결측치 처리 방법
     
     1. 결측값 무시하기
     
     2. 결측값 추정 방법평
        
        * 회귀분석, 베이지안, 의사결정트리 기법 등의 통계 또는 마이닝 기법을 활용하여 결측값을 예측한다.

### 3. 데이터 이상값 처리

* 1. 구간화(Binning)
     
     정렬된 데이터 값을들 몇 개의 빈(Bin, 혹은 버킷)으로 분할하여 평활하하는 방법, 즉 평평하게 만드는 작업이다.
  
  2. 회귀(Regression)
  
  3. 군집화(Clustering)

### 4. 분석 변수 처리

1. 변수 선택

2. 차원 축소 기법(Dimensionality Reduction)
   
   1. 개념 및 목적
   
   2. 활용 분야
   
   3. 연관성 분석(장바구니 분석)
      
      1. 지지도(Support)
      
      2. 신뢰도(Confidence)
      
      3. 향상도(Lift)

3. 파생(유도)변수 생성
   
   1. 파생변수 개념

4. 변수 변환
   
   1. 분석 모형 및 자료 변환
   
   2. 텍스트 마이닝에서 자료 변환 방법
      
      1. 형태소 분석
         
         * 형태소는 의미가 있는 최소의 단위로서 더 이상 분리가 불가능한 가장 작은 의미의 요소이다.
      
      2. 텍스트 전처리(Pre-Processing)
         
         * 텍스트 분석을 위해 문장 분리, 불필요한 문장 성분을 제거하는 과정이다.
      
      3. 품사 태깅
         
         * 품사 태깅(POS Tagging; Part-Of-Speech Tagging)은 품사의 모호성을 제거하는 통계적 모델인 은닉 마르코프 모델(HMM; Hidden Markov Model)을 많이 이용한다.

5. 불균형 데이터 처리
   
   1. 과대적합
   
   2. 과대적합 방지

## CHAPTER 2 데이터 탐색

### 1. 데이터 탐색 개념

1. 데이터 탐색 개념
   
   <데이터 탐색을 위해 활용되는 빅데이터 기술>
   
   1. 상관관계 분석
      
      1. 상관관계
         
         * 상관계수(correlation coefficient)는 변수 간의 관계 정도나 방향을 하나의 수치로 요약해 표시해 주는 지수이다.
      
      2. 상관계수의 성질
         
         1. 명목 척도
         
         2. 서열척도
         
         3. 등간척도
         
         4. 비율 척도
      
      3. 상관 분석
         
         * 두 변수 사이의 관계를 측정하고 묘사하기 위해 이용되는 통계학의 한 기법을 상관 분석이라고 한다.
   
   2. 탐색적 데이터 분석
      
      * 탐색적 데이터 분석은 영어로는 EDA(Exploratory Data Analytsis)이다. 데이터의 특징과 내재하는 구조적 관계를 알아내기 위한 기법들을 총칭하는 것을 의미한다.

2. 기초통계량

3. 시각화를 통한 탐색적 자료분석
   
   * 데이터의 풍부함을 드러내기 위한 새로운 방식이며, 방대한 양의 데이터를 탐색하거나 이해할 때 가장 효율적으로 시각화(Visualization)를 실천한다.
   
   시간 시각화, 분포 시각화, 관계 시각화, 비교 시각화, 공간 시각화, 인포그래픽 기법
   
   1. 시간 시각화
      
      1. 경제 활동과 관련된 시계열
      
      2. 물리적 현상과 관련된 시계열
      
      3. 기업의 경영 활동과 관련된 시계열
      
      4. 인구 관련 시계열
      
      5. 품질관리 등 생산관리와 관련된 시계열
      
      6. 통신공학 또는 공학과 관련된 시계열
      
      7. 사회생활과 관련된 시계열
   
   2. 분포 시각화
   
   3. 관계 시각화
   
   4. 비교 시각화
   
   5. 인포그래픽

4. 다중공선성
   
   1. 개념
      
      1. 입력 변수간의 상관관계가 높은 것을 의미
   
   2. 다중공선성 진단 방법
   
   3. 다중공선성 해결 방법

### 2. 고급 데이터 탐색

1. 시공간 데이터 탐색
   
   1. 시공간 데이터의 정의 및 특징
      
      <시공간 데이터의 구분>
      
      <시공간 데이터의 타입>
   
   2. 시공간 통계 및 클러스터링 알고리즘 조사 분석
      
      1. 공간자기상관성
         
         * 지리적 공간성에서 공간객체 간의 상호의존성과 상호작용을 나타낸다.
      
      2. 로지스틱 회귀 모형
      
      3. ARIMA 모형
         
         * ARIMA 모형은 어느 정도의 시차를 가지고 어떤 변수가 다른 어떤 변수에 얼마나 영향을 미쳤는지를 분석해낼 수 있는 모형이며, 자기회귀(AR; Auto-Regressive) 모형과 이동 평균(MA; Moving Average) 모형을 결합한 시계열분석 모형이다.
      
      4. 클러스터링 알고리즘
         
         1. 비계층
